# å¤šè§†è§’ SSDD è®­ç»ƒå®Œæ•´æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

ä»é›¶å¼€å§‹è®­ç»ƒå¤šè§†è§’ SSDD æ¨¡å‹ã€‚

---

## ğŸ“‹ å‰ç½®æ£€æŸ¥æ¸…å•

### 1. ç¯å¢ƒæ£€æŸ¥

```bash
# æ£€æŸ¥ Python ç‰ˆæœ¬ (éœ€è¦ >= 3.11)
python --version

# æ£€æŸ¥ PyTorch å’Œ CUDA
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"

# æ£€æŸ¥ accelerate
accelerate --version
```

### 2. æ•°æ®æ£€æŸ¥

```bash
# æ£€æŸ¥æ•°æ®ç›®å½•
ls -lh /data/360SP-data/train | head -10
ls -lh /data/360SP-data/val | head -10

# ç»Ÿè®¡æ•°æ®é‡
echo "è®­ç»ƒé›†å›¾ç‰‡æ•°é‡: $(ls /data/360SP-data/train/*.jpg | wc -l)"
echo "éªŒè¯é›†å›¾ç‰‡æ•°é‡: $(ls /data/360SP-data/val/*.jpg | wc -l)"
```

**æœŸæœ›è¾“å‡º**:
```
è®­ç»ƒé›†å›¾ç‰‡æ•°é‡: 1000000
éªŒè¯é›†å›¾ç‰‡æ•°é‡: 50000
```

### 3. GPU æ£€æŸ¥

```bash
# æŸ¥çœ‹ GPU ä¿¡æ¯
nvidia-smi

# æ£€æŸ¥å¯ç”¨ GPU æ•°é‡
python -c "import torch; print(f'Available GPUs: {torch.cuda.device_count()}')"
```

---

## ğŸ¯ ä¸‰ç§è®­ç»ƒæ¨¡å¼

### æ¨¡å¼ 1: ä»å¤´è®­ç»ƒ (ä¸ä½¿ç”¨ Teacher)

**é€‚ç”¨åœºæ™¯**: é¦–æ¬¡è®­ç»ƒï¼Œæ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹

```bash
accelerate launch ssdd/main_multiview.py \
    run_name=multiview_from_scratch \
    distill_teacher=false \
    training.epochs=100 \
    dataset.im_size=128 \
    dataset.batch_size=256
```

**é¢„ä¼°æ—¶é—´**: 24-48 å°æ—¶ (4Ã—A100)

---

### æ¨¡å¼ 2: Teacher-Student è’¸é¦ (æ¨è)

**é€‚ç”¨åœºæ™¯**: å·²æœ‰ teacher æ¨¡å‹ï¼Œæƒ³è®­ç»ƒå¿«é€Ÿçš„ student

#### æ­¥éª¤ 2.1: è®­ç»ƒ Teacher (å¦‚æœè¿˜æ²¡æœ‰)

```bash
# è®­ç»ƒå¤šæ­¥ teacher æ¨¡å‹
accelerate launch ssdd/main.py \
    run_name=teacher_12steps \
    training.epochs=100 \
    dataset.im_size=128 \
    ssdd.fm_sampler.steps=12 \
    ssdd.encoder=f8c4 \
    ssdd.decoder=M
```

**æ—¶é—´**: ~24 å°æ—¶

#### æ­¥éª¤ 2.2: è’¸é¦è®­ç»ƒ Student

```bash
# ä½¿ç”¨ teacher è’¸é¦è®­ç»ƒ student (å•æ­¥)
accelerate launch ssdd/main_multiview.py \
    run_name=student_1step_distill \
    distill_teacher=true \
    ssdd.checkpoint=teacher_12steps@best \
    ssdd.fm_sampler.steps=12 \
    training.epochs=10 \
    training.lr=1e-4 \
    training.eval_freq=1
```

**æ—¶é—´**: ~3 å°æ—¶

---

### æ¨¡å¼ 3: å¿«é€Ÿæµ‹è¯• (å°æ•°æ®é›†)

**é€‚ç”¨åœºæ™¯**: éªŒè¯æµç¨‹ã€è°ƒè¯•ä»£ç 

```bash
accelerate launch ssdd/main_multiview.py \
    run_name=test_run \
    distill_teacher=false \
    dataset.limit=1000 \
    training.epochs=5 \
    training.eval_freq=1 \
    training.log_freq=10 \
    dataset.batch_size=32
```

**æ—¶é—´**: ~10 åˆ†é’Ÿ

---

## ğŸ”§ è¯¦ç»†é…ç½®è¯´æ˜

### å…³é”®å‚æ•°

#### æ•°æ®é›†å‚æ•°

```yaml
dataset:
  imagenet_root: /data/360SP-data  # æ•°æ®æ ¹ç›®å½•
  im_size: 128                      # å›¾åƒå¤§å° (128 æ¨è)
  batch_size: 256                   # æ€»æ‰¹é‡å¤§å° (ä¼šè‡ªåŠ¨åˆ†é…åˆ°å¤š GPU)
  limit: null                       # é™åˆ¶æ ·æœ¬æ•° (null=å…¨éƒ¨, 1000=æµ‹è¯•)
  return_all_views: true            # å¿…é¡»ä¸º true (å¤šè§†è§’æ¨¡å¼)

  # EquiDataset å‚æ•°
  f_pix: 220.0                      # UCM ç„¦è·
  xi: 0.9                           # UCM é•œé¢å‚æ•°
  mask_mode: inscribed              # åœ†å½¢é®ç½©æ¨¡å¼
```

#### æ¨¡å‹å‚æ•°

```yaml
ssdd:
  encoder: f8c4                     # f8=patch_size_8, c4=z_dim_4
  encoder_train: false              # æ˜¯å¦è®­ç»ƒ encoder (é€šå¸¸ false)
  decoder: M                        # è§£ç å™¨å¤§å° (XS/S/M/L/XL)

  # å¤šè§†è§’å‚æ•°
  n_views: 4                        # è§†è§’æ•°é‡
  fusion_type: concat_conv          # èåˆç­–ç•¥
  use_view_encoding: true           # å¯ç”¨è§†è§’ç¼–ç 
  view_encoding_type: sinusoidal    # ç¼–ç ç±»å‹ (å½“å‰é…ç½®)

  # Flow Matching å‚æ•°
  fm_sampler:
    steps: 12                       # é‡‡æ ·æ­¥æ•° (teacherç”¨12, evalç”¨1)
```

#### è®­ç»ƒå‚æ•°

```yaml
training:
  mixed_precision: bf16             # æ··åˆç²¾åº¦ (bf16/fp16/no)
  grad_accumulate: 1                # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
  grad_clip: 0.1                    # æ¢¯åº¦è£å‰ª
  epochs: 300                       # è®­ç»ƒè½®æ•°
  eval_freq: 4                      # è¯„ä¼°é¢‘ç‡ (æ¯4ä¸ªepoch)
  save_on_best: FID                 # ä¿å­˜æœ€ä½³æ¨¡å‹çš„æŒ‡æ ‡
  log_freq: 200                     # æ—¥å¿—é¢‘ç‡ (æ¯200æ­¥)

  lr: 8e-4                          # å­¦ä¹ ç‡
  weight_decay: 1e-2                # æƒé‡è¡°å‡
```

---

## ğŸ“Š ç›‘æ§è®­ç»ƒ

### æ–¹å¼ 1: TensorBoard (æ¨è)

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir=tensorboard_logs --port=6006

# åœ¨æµè§ˆå™¨æ‰“å¼€
# http://localhost:6006
```

**ç›‘æ§æŒ‡æ ‡**:
- `Loss/average`: å¹³å‡è®­ç»ƒæŸå¤±
- `Loss/diffusion`: æ‰©æ•£æŸå¤±
- `Loss/repa`: REPA æ„ŸçŸ¥æŸå¤±
- `Loss/lpips`: LPIPS æ„ŸçŸ¥æŸå¤±
- `metric/FID`: FrÃ©chet Inception Distance
- `metric/PSNR`: Peak Signal-to-Noise Ratio

---

### æ–¹å¼ 2: æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶

```bash
# æŸ¥çœ‹æœ€æ–°çš„è®­ç»ƒæ—¥å¿—
tail -f runs/jobs/*/main_multiview.log

# æŸ¥çœ‹è®­ç»ƒè¿›åº¦
grep "End of epoch" runs/jobs/*/main_multiview.log

# æŸ¥çœ‹æœ€ä½³æŒ‡æ ‡
grep "Best metrics" runs/jobs/*/main_multiview.log
```

---

### æ–¹å¼ 3: å®æ—¶è¾“å‡º

è®­ç»ƒæ—¶ä¼šè‡ªåŠ¨æ˜¾ç¤ºè¿›åº¦ï¼š

```
[T_total=00:15:32 | T_train=00:12:45 | T_epoch=00:02:15]
Epoch 10, batch 200 / 1000 (step 2000)
loss=0.0235 (avg=0.0245) [[all losses: diffusion=0.0180 ; repa=0.0035 ; lpips=0.0020]]
```

---

## ğŸ›ï¸ å¸¸ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–

### è°ƒæ•´æ‰¹é‡å¤§å°

```bash
# å‡å°æ‰¹é‡å¤§å° (å†…å­˜ä¸è¶³æ—¶)
accelerate launch ssdd/main_multiview.py \
    dataset.batch_size=128

# ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
accelerate launch ssdd/main_multiview.py \
    dataset.batch_size=128 \
    training.grad_accumulate=2  # ç­‰æ•ˆäº batch_size=256
```

### è°ƒæ•´å­¦ä¹ ç‡

```bash
# ä½¿ç”¨æ›´å¤§çš„å­¦ä¹ ç‡ (ä»å¤´è®­ç»ƒ)
accelerate launch ssdd/main_multiview.py \
    training.lr=1e-3

# ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡ (å¾®è°ƒ/è’¸é¦)
accelerate launch ssdd/main_multiview.py \
    training.lr=5e-5
```

### åˆ‡æ¢ View Encoding ç±»å‹

```bash
# ä½¿ç”¨ Learnable Encoding
accelerate launch ssdd/main_multiview.py \
    ssdd.view_encoding_type=learnable

# ä½¿ç”¨ Sinusoidal Encoding (å½“å‰é»˜è®¤)
accelerate launch ssdd/main_multiview.py \
    ssdd.view_encoding_type=sinusoidal

# ä½¿ç”¨ Directional Encoding
accelerate launch ssdd/main_multiview.py \
    ssdd.view_encoding_type=directional

# ç¦ç”¨ View Encoding (æ¶ˆèå®éªŒ)
accelerate launch ssdd/main_multiview.py \
    ssdd.use_view_encoding=false
```

### åˆ‡æ¢ Fusion ç­–ç•¥

```bash
# Concat+Conv (é»˜è®¤)
accelerate launch ssdd/main_multiview.py \
    ssdd.fusion_type=concat_conv

# Attention-based
accelerate launch ssdd/main_multiview.py \
    ssdd.fusion_type=attention

# Simple Average (baseline)
accelerate launch ssdd/main_multiview.py \
    ssdd.fusion_type=average
```

---

## ğŸ—‚ï¸ è¾“å‡ºæ–‡ä»¶ç»“æ„

è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
runs/
â””â”€â”€ jobs/
    â””â”€â”€ multiview_from_scratch/  # run_name
        â”œâ”€â”€ checkpoints/
        â”‚   â”œâ”€â”€ checkpoint_epoch_10.pt
        â”‚   â”œâ”€â”€ checkpoint_epoch_20.pt
        â”‚   â””â”€â”€ checkpoint_best.pt  # æœ€ä½³æ¨¡å‹
        â”œâ”€â”€ plots/
        â”‚   â”œâ”€â”€ generation_epoch=10.png
        â”‚   â””â”€â”€ generation_epoch=20.png
        â”œâ”€â”€ config.yaml  # å®é™…ä½¿ç”¨çš„é…ç½®
        â”œâ”€â”€ main_multiview.log  # è®­ç»ƒæ—¥å¿—
        â””â”€â”€ task_result.json  # è¯„ä¼°ç»“æœ

tensorboard_logs/
â””â”€â”€ events.out.tfevents.*  # TensorBoard æ—¥å¿—
```

---

## ğŸ”„ æ¢å¤è®­ç»ƒ

å¦‚æœè®­ç»ƒä¸­æ–­ï¼Œå¯ä»¥è‡ªåŠ¨æ¢å¤ï¼š

```bash
# ä½¿ç”¨ç›¸åŒçš„ run_name ä¼šè‡ªåŠ¨åŠ è½½ checkpoint
accelerate launch ssdd/main_multiview.py \
    run_name=multiview_from_scratch
```

ç³»ç»Ÿä¼šè‡ªåŠ¨ï¼š
1. æ£€æµ‹ `runs/jobs/multiview_from_scratch/checkpoints/` æ˜¯å¦å­˜åœ¨
2. åŠ è½½æœ€æ–°çš„ checkpoint
3. ä»ä¸­æ–­çš„ epoch ç»§ç»­è®­ç»ƒ

---

## ğŸ¯ å®Œæ•´è®­ç»ƒæµç¨‹ç¤ºä¾‹

### åœºæ™¯: ä»é›¶å¼€å§‹è®­ç»ƒå¤šè§†è§’æ¨¡å‹

#### ç¬¬ 1 æ­¥: æ•°æ®éªŒè¯

```bash
# æµ‹è¯•æ•°æ®åŠ è½½ (1åˆ†é’Ÿ)
python -c "
from ssdd.dataset_equi import load_equirect

cfg = {
    'imagenet_root': '/data/360SP-data',
    'im_size': 128,
    'batch_size': 4,
    'limit': 10,
    'return_all_views': True,
}

(train_ds, test_ds), (train_loader, test_loader) = load_equirect(cfg)
print(f'âœ“ è®­ç»ƒé›†: {len(train_ds)} æ ·æœ¬')
print(f'âœ“ æµ‹è¯•é›†: {len(test_ds)} æ ·æœ¬')

for views, panorama in train_loader:
    print(f'âœ“ Views shape: {views.shape}')
    print(f'âœ“ Panorama shape: {panorama.shape}')
    break
"
```

**æœŸæœ›è¾“å‡º**:
```
âœ“ è®­ç»ƒé›†: 10 æ ·æœ¬
âœ“ æµ‹è¯•é›†: 10 æ ·æœ¬
âœ“ Views shape: torch.Size([4, 4, 3, 128, 128])
âœ“ Panorama shape: torch.Size([4, 3, 256, 128])
```

---

#### ç¬¬ 2 æ­¥: å¿«é€Ÿæµ‹è¯• (å¯é€‰)

```bash
# å°è§„æ¨¡æµ‹è¯• (10åˆ†é’Ÿ)
accelerate launch ssdd/main_multiview.py \
    run_name=quick_test \
    dataset.limit=100 \
    training.epochs=2 \
    training.eval_freq=1 \
    dataset.batch_size=8
```

æ£€æŸ¥æ˜¯å¦æœ‰æŠ¥é”™ã€‚

---

#### ç¬¬ 3 æ­¥: å®Œæ•´è®­ç»ƒ

```bash
# å®Œæ•´è®­ç»ƒ (24-48å°æ—¶)
accelerate launch ssdd/main_multiview.py \
    run_name=multiview_production_v1 \
    distill_teacher=false \
    training.epochs=100 \
    dataset.batch_size=256 \
    training.eval_freq=4 \
    ssdd.view_encoding_type=learnable \
    ssdd.fusion_type=concat_conv
```

---

#### ç¬¬ 4 æ­¥: ç›‘æ§å’Œè°ƒä¼˜

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼š

```bash
# ç»ˆç«¯ 1: æŸ¥çœ‹æ—¥å¿—
tail -f runs/jobs/multiview_production_v1/main_multiview.log

# ç»ˆç«¯ 2: TensorBoard
tensorboard --logdir=tensorboard_logs

# ç»ˆç«¯ 3: æŸ¥çœ‹ GPU ä½¿ç”¨ç‡
watch -n 1 nvidia-smi
```

---

#### ç¬¬ 5 æ­¥: è¯„ä¼°

```bash
# è¯„ä¼°æœ€ä½³æ¨¡å‹
accelerate launch ssdd/main_multiview.py \
    task=eval \
    ssdd.checkpoint=multiview_production_v1@best \
    ssdd.fm_sampler.steps=1  # å•æ­¥æ¨ç†
```

---

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜ 1: CUDA Out of Memory

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ–¹æ¡ˆ A: å‡å°æ‰¹é‡å¤§å°
accelerate launch ssdd/main_multiview.py \
    dataset.batch_size=128

# æ–¹æ¡ˆ B: ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
accelerate launch ssdd/main_multiview.py \
    dataset.batch_size=64 \
    training.grad_accumulate=4

# æ–¹æ¡ˆ C: å‡å°å›¾åƒå°ºå¯¸
accelerate launch ssdd/main_multiview.py \
    dataset.im_size=96

# æ–¹æ¡ˆ D: ä½¿ç”¨ fp16 æ··åˆç²¾åº¦
accelerate launch ssdd/main_multiview.py \
    training.mixed_precision=fp16
```

---

### é—®é¢˜ 2: æ•°æ®åŠ è½½æ…¢

**ç—‡çŠ¶**: è®­ç»ƒå¡åœ¨æ•°æ®åŠ è½½

**è§£å†³æ–¹æ¡ˆ**:

```bash
# å‡å°‘ num_workers (å¦‚æœ CPU ä¸å¤Ÿ)
# ä¿®æ”¹ dataset_equi.py:173
num_workers=4  # ä» 10 æ”¹ä¸º 4

# æˆ–ç¦ç”¨ persistent_workers
persistent_workers=False
```

---

### é—®é¢˜ 3: Teacher checkpoint æœªæ‰¾åˆ°

**ç—‡çŠ¶**:
```
FileNotFoundError: teacher checkpoint not found
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ£€æŸ¥ checkpoint æ˜¯å¦å­˜åœ¨
ls runs/jobs/teacher_12steps/checkpoints/

# ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
accelerate launch ssdd/main_multiview.py \
    ssdd.checkpoint=runs/jobs/teacher_12steps/checkpoints/checkpoint_best.pt

# æˆ–ç¦ç”¨ teacher
accelerate launch ssdd/main_multiview.py \
    distill_teacher=false
```

---

### é—®é¢˜ 4: è®­ç»ƒæŸå¤±ä¸ä¸‹é™

**å¯èƒ½åŸå› **:
1. å­¦ä¹ ç‡è¿‡å¤§æˆ–è¿‡å°
2. æ•°æ®é—®é¢˜
3. æ¨¡å‹é…ç½®é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:

```bash
# å°è¯•è°ƒæ•´å­¦ä¹ ç‡
accelerate launch ssdd/main_multiview.py \
    training.lr=5e-4  # æˆ– 1e-3, 1e-5

# æ£€æŸ¥æ•°æ®
python utils/EquiDataset.py  # è¿è¡Œæµ‹è¯•

# æ£€æŸ¥æ¢¯åº¦
# åœ¨è®­ç»ƒæ—¥å¿—ä¸­æŸ¥æ‰¾ "grad_norm"
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. GPU åˆ©ç”¨ç‡ä¼˜åŒ–

```bash
# æœ€å¤§åŒ–æ‰¹é‡å¤§å°
accelerate launch ssdd/main_multiview.py \
    dataset.batch_size=512  # æ ¹æ® GPU å†…å­˜è°ƒæ•´

# å¯ç”¨ TF32 (Ampere+ GPU)
# å·²åœ¨ SpiderTask_MultiView.py ä¸­é»˜è®¤å¯ç”¨
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
```

---

### 2. å¤š GPU è®­ç»ƒ

```bash
# ä½¿ç”¨ accelerate é…ç½®
accelerate config

# é€‰æ‹©:
# - multi-GPU
# - ä½¿ç”¨çš„ GPU æ•°é‡
# - æ··åˆç²¾åº¦: bf16

# ç„¶åæ­£å¸¸å¯åŠ¨è®­ç»ƒ
accelerate launch ssdd/main_multiview.py \
    run_name=multigpu_training
```

---

### 3. ç¼–è¯‘ä¼˜åŒ–

```bash
# å¯ç”¨ torch.compile (PyTorch 2.0+)
# å·²åœ¨é…ç½®ä¸­é»˜è®¤å¯ç”¨
ssdd.compile=true

# å¦‚æœé‡åˆ°ç¼–è¯‘é—®é¢˜ï¼Œå¯ä»¥ç¦ç”¨
accelerate launch ssdd/main_multiview.py \
    ssdd.compile=false
```

---

## ğŸ“ è®­ç»ƒæ£€æŸ¥æ¸…å•

å¼€å§‹è®­ç»ƒå‰ï¼Œç¡®è®¤ï¼š

- [ ] æ•°æ®è·¯å¾„æ­£ç¡®: `/data/360SP-data/train` å’Œ `/data/360SP-data/val` å­˜åœ¨
- [ ] æ•°æ®æ ¼å¼æ­£ç¡®: ç­‰è·åœ†æŸ±æŠ•å½±å…¨æ™¯å›¾ï¼Œ`.jpg` æ ¼å¼
- [ ] GPU å¯ç”¨: `nvidia-smi` æ˜¾ç¤º GPU
- [ ] ç¯å¢ƒæ­£ç¡®: PyTorch, accelerate å·²å®‰è£…
- [ ] é…ç½®å·²æ›´æ–°: `config/SpiderEye.yaml` ä¸­çš„å‚æ•°ç¬¦åˆé¢„æœŸ
- [ ] ç£ç›˜ç©ºé—´å……è¶³: è‡³å°‘ 100GB (checkpoints + logs)
- [ ] TensorBoard å·²å¯åŠ¨: å®æ—¶ç›‘æ§è®­ç»ƒ

---

## ğŸš€ æ¨èè®­ç»ƒå‘½ä»¤

### ç”Ÿäº§ç¯å¢ƒ (æ¨è)

```bash
# å®Œæ•´è®­ç»ƒï¼ŒLearnable View Encodingï¼ŒConcat+Conv Fusion
accelerate launch ssdd/main_multiview.py \
    run_name=prod_learnable_concat_$(date +%Y%m%d_%H%M%S) \
    distill_teacher=false \
    training.epochs=100 \
    training.eval_freq=4 \
    ssdd.view_encoding_type=learnable \
    ssdd.fusion_type=concat_conv \
    dataset.batch_size=256
```

### å¿«é€Ÿå®éªŒ

```bash
# å¿«é€Ÿè¿­ä»£ï¼ŒSinusoidal Encoding
accelerate launch ssdd/main_multiview.py \
    run_name=exp_sinusoidal_$(date +%Y%m%d_%H%M%S) \
    dataset.limit=10000 \
    training.epochs=20 \
    training.eval_freq=2 \
    ssdd.view_encoding_type=sinusoidal \
    dataset.batch_size=128
```

---

## ğŸ“ è·å–å¸®åŠ©

é‡åˆ°é—®é¢˜ï¼ŸæŸ¥çœ‹ï¼š

1. **æ—¥å¿—æ–‡ä»¶**: `runs/jobs/*/main_multiview.log`
2. **é…ç½®æ–‡ä»¶**: `runs/jobs/*/config.yaml`
3. **æ–‡æ¡£**:
   - `VIEW_ENCODING_GUIDE.md` - View Encoding è¯¦è§£
   - `MULTIVIEW_ARCHITECTURE.md` - æ¶æ„è¯´æ˜
   - `QUICK_START_MULTIVIEW.md` - å¿«é€Ÿä¸Šæ‰‹

---

## âœ… æˆåŠŸè®­ç»ƒçš„æ ‡å¿—

å¦‚æœçœ‹åˆ°ä»¥ä¸‹è¾“å‡ºï¼Œè¯´æ˜è®­ç»ƒæ­£å¸¸ï¼š

```
âœ“ Loaded EquiDataset (multi-view): {'train': ..., 'test': ...}
âœ“ ae parameters count: Total: #... (trainable: #...)
âœ“ [Epoch 1] End of epoch ... train loss ...
âœ“ [Epoch 1] Test metrics: FID=... PSNR=... LPIPS=...
âœ“ Saved checkpoint to .../checkpoint_epoch_1.pt
âœ“ [Epoch 1] Best metrics: FID=... (best)
```

---

ğŸ‰ **å¼€å§‹è®­ç»ƒå§ï¼**

```bash
accelerate launch ssdd/main_multiview.py \
    run_name=my_first_multiview_training
```
